{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/raw/data_carrers.csv'\n",
    "OUTPUT_PATH = '../data/processed/processed-dataset.csv'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, AdamW, get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "\n",
    "# 1) Modelo para traducir de español a inglés\n",
    "model_name_es_en = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "translator_es_en = pipeline(\n",
    "    \"translation_es_to_en\",\n",
    "    model=model_name_es_en,\n",
    "    tokenizer=model_name_es_en\n",
    ")\n",
    "\n",
    "# 2) Modelo para traducir de inglés a español\n",
    "model_name_en_es = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "translator_en_es = pipeline(\n",
    "    \"translation_en_to_es\",\n",
    "    model=model_name_en_es,\n",
    "    tokenizer=model_name_en_es\n",
    ")\n",
    "\n",
    "def manual_back_translation(text, translator_es_en, translator_en_es):\n",
    "    # 1) Traducir de español a inglés\n",
    "    result_en = translator_es_en(text, max_length=512, truncation=True)\n",
    "    # result_en es una lista de diccionarios [{'translation_text': \"...\"}]\n",
    "    text_en = result_en[0][\"translation_text\"]\n",
    "\n",
    "    # 2) Traducir la versión en inglés de vuelta a español\n",
    "    result_es = translator_en_es(text_en, max_length=512, truncation=True)\n",
    "    text_es = result_es[0][\"translation_text\"]\n",
    "\n",
    "    return text_es\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(DATASET_PATH, encoding=\"UTF-8\")\n",
    "\n",
    "\n",
    "df_augmented_texts = []\n",
    "df_augmented_labels = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    original_text = row['TEXTO']\n",
    "    label = row['CARRERA']\n",
    "\n",
    "    # Genera, por ejemplo, 1 o 2 versiones back-translated\n",
    "    # ¡Ojo! Esto puede ser lento si tu dataset es grande\n",
    "    for _ in range(2):\n",
    "        # Ejecutar la traducción ida y vuelta\n",
    "        back_translated = manual_back_translation(\n",
    "            original_text,\n",
    "            translator_es_en,\n",
    "            translator_en_es\n",
    "        )\n",
    "        df_augmented_texts.append(back_translated)\n",
    "        df_augmented_labels.append(label)\n",
    "\n",
    "# Crear el df de ejemplos aumentados\n",
    "df_aug = pd.DataFrame({\n",
    "    'TEXTO': df_augmented_texts,\n",
    "    'CARRERA': df_augmented_labels\n",
    "})\n",
    "\n",
    "# Concatenar con el original\n",
    "df_final = pd.concat([df, df_aug]).reset_index(drop=True)\n",
    "\n",
    "df = df_final\n",
    "\n",
    "\n",
    "# Eliminar valores nulos y duplicados\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "# Preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\sáéíóúñü]', '', text)  # Elimina caracteres especiales pero mantiene caracteres acentuados\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Reemplaza múltiples espacios por uno solo\n",
    "    text = text.strip()  # Elimina espacios en blanco al inicio y al final\n",
    "    return text\n",
    "\n",
    "\n",
    "df['TEXTO'] = df['TEXTO'].apply(preprocess_text)\n",
    "\n",
    "# Mapear las categorías a índices numéricos\n",
    "print(df['CARRERA'].unique())\n",
    "categories = df['CARRERA'].unique().tolist()\n",
    "category_to_index = {category: idx for idx, category in enumerate(categories)}\n",
    "df['LABEL'] = df['CARRERA'].map(category_to_index)\n",
    "\n",
    "texts = df['TEXTO'].tolist()\n",
    "labels = df['LABEL'].tolist()\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_mask, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir tensores a numpy arrays\n",
    "input_ids_np = input_ids.numpy()\n",
    "attention_mask_np = attention_mask.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# División en entrenamiento+validación y prueba\n",
    "X_train_val, X_test, y_train_val, y_test, mask_train_val, mask_test = train_test_split(\n",
    "    input_ids_np, labels_np, attention_mask_np, test_size=0.2, random_state=42, stratify=labels_np)\n",
    "\n",
    "# División en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val, mask_train, mask_val = train_test_split(\n",
    "    X_train_val, y_train_val, mask_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
    "\n",
    "print(y_train, y_val.shape, y_test.shape)\n",
    "# Convertir a tensores\n",
    "train_dataset = TensorDataset(torch.tensor(X_train,dtype=torch.long), torch.tensor(mask_train,dtype=torch.long), torch.tensor(y_train,dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val,dtype=torch.long), torch.tensor(mask_val,dtype=torch.long), torch.tensor(y_val,dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.long), torch.tensor(mask_test, dtype=torch.long), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "config = BertConfig.from_pretrained('dccuchile/bert-base-spanish-wwm-cased', \n",
    "                                    num_labels=len(category_to_index), \n",
    "                                    hidden_dropout_prob=0.3, \n",
    "                                    attention_probs_dropout_prob=0.3)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-cased', config=config)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "\n",
    "# Suponiendo que 'y_train' contiene las etiquetas de entrenamiento\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUCLE DE ENTRENAMIENTO\n",
    "\n",
    "epochs = 45\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "# Configurar el modelo en modo de entrenamiento\n",
    "\n",
    "patience = 3\n",
    "early_stopping_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Después de calcular class_weights\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "loss_fn = CrossEntropyLoss(weight=class_weights)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_accuracies = []\n",
    "training_accuracies = []\n",
    "training_f1_scores = []\n",
    "validation_f1_scores = []  # Agrega esta línea aquí\n",
    "learning_rates = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Entrenamiento ###\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_predictions = []\n",
    "    train_true_labels = []\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} - Entrenamiento\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "                # Almacenar predicciones y etiquetas\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        train_predictions.extend(preds.cpu().numpy())\n",
    "        train_true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "    learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Calcular métricas de entrenamiento\n",
    "    train_accuracy = accuracy_score(train_true_labels, train_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    train_true_labels, train_predictions, average='weighted')\n",
    "    training_accuracies.append(train_accuracy)\n",
    "    training_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "    ### Validación ###\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_predictions = []\n",
    "    val_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_dataloader, desc=f\"Epoch {epoch+1}/{epochs} - Validación\"):\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            val_predictions.extend(preds.cpu().numpy())\n",
    "            val_true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "    validation_losses.append(avg_val_loss)\n",
    "\n",
    "    # Calcular precisión en validación\n",
    "    val_accuracy = accuracy_score(val_true_labels, val_predictions)\n",
    "    validation_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Después de calcular avg_val_loss y val_accuracy, agrega:\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        val_true_labels, val_predictions, average='weighted')\n",
    "    validation_f1_scores.append(f1)\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Pérdida Entrenamiento: {avg_train_loss:.4f}, Pérdida Validación: {avg_val_loss:.4f}, Precisión Validación: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Definir variables para Early Stopping\n",
    "    # Early Stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')  # Guarda el mejor modelo\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"No hay mejora en la pérdida de validación. Paciencia: {early_stopping_counter}/{patience}\")\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early Stopping activado\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el mejor modelo\n",
    "model.load_state_dict(torch.load('best_model_state.bin', weights_only=True))\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluación en Conjunto de Prueba\"):\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_predictions.extend(preds.cpu().numpy())\n",
    "        test_true_labels.extend(labels.cpu().numpy()) \n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_true_labels, test_predictions, target_names=categories))\n",
    "\n",
    "  \n",
    "## MONITOREO DE GRÁFICOS Y METRICAS\n",
    "\n",
    "epochs_range = range(1, len(training_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "#generar matriz de confusion para la justificacion de la escogencia del algoritmo\n",
    "\n",
    "######CODIGO A IMPLEMENTAR ######\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Obtener la matriz de confusión en el conjunto de validación\n",
    "conf_matrix = confusion_matrix(val_true_labels, val_predictions)\n",
    "\n",
    "# Visualizar la matriz de confusión con un heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "# generar la grafica de learning rate (curva de aprendizaje)\n",
    "\n",
    "\n",
    "# Graficar la tasa de aprendizaje durante el entrenamiento\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs+1), learning_rates, label=\"Tasa de Aprendizaje\")\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Tasa de Aprendizaje')\n",
    "plt.title('Curva de Tasa de Aprendizaje durante el Entrenamiento')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "####### CODIGO A IMPLEMENTAR ######\n",
    "\n",
    "# Gráfica de pérdidas\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs_range, training_losses, label='Pérdida de Entrenamiento')\n",
    "plt.plot(epochs_range, validation_losses, label='Pérdida de Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.title('Pérdida por Época')\n",
    "\n",
    "# Gráfica de precisión\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_range, training_accuracies, label='Precisión de Entrenamiento')\n",
    "plt.plot(epochs_range, validation_accuracies, label='Precisión de Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.legend()\n",
    "plt.title('Precisión por Época')\n",
    "\n",
    "# Gráfica de F1-score\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs_range, training_f1_scores, label='F1-score de Entrenamiento')\n",
    "plt.plot(epochs_range, validation_f1_scores, label='F1-score de Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend()\n",
    "plt.title('F1-score por Época')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reforzar la justificación de la implementación, podrías generar más gráficas que incluyan:\n",
    "\n",
    "Curva ROC y AUC:\n",
    "\n",
    "La Curva ROC (Receiver Operating Characteristic) muestra el rendimiento del modelo en clasificación binaria, y el AUC (Area Under Curve) indica qué tan bien puede distinguir el modelo entre las clases. Esto es especialmente útil si estás trabajando con clasificación binaria (por ejemplo, clasificar respuestas como positivas o negativas).\n",
    "Matriz de confusión:\n",
    "\n",
    "La matriz de confusión te muestra cómo el modelo está clasificando las respuestas en cada clase. Esto puede proporcionar una comprensión más profunda de cómo el modelo está manejando cada categoría de respuesta en el contexto de orientación vocacional.\n",
    "Learning Rate Curve:\n",
    "\n",
    "Una gráfica del learning rate a lo largo del tiempo puede proporcionar información sobre cómo la tasa de aprendizaje está influyendo en el rendimiento del modelo.\n",
    "¿Te gustaría que genere alguna de estas gráficas adicionales para complementar la justificación del modelo que has implementado?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
