{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el entorno y carga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_19200\\207714581.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Mapea índice -> categoría (lo que usaste en training)\n",
    "index_to_category = {\n",
    "    0: \"INDUSTRIAL\", \n",
    "    1: \"CIVIL\", \n",
    "    2: \"INFORMÁTICA\",\n",
    "    3: \"TELECOMUNICACIONES\",\n",
    "    4: \"ARQUITECTURA\",\n",
    "    5: \"FILOSOFÍA\",\n",
    "    6: \"PSICOLOGÍA\",\n",
    "    7: \"LETRAS\",\n",
    "    8: \"COMUNICACIÓN SOCIAL\",\n",
    "    9: \"EDUCACIÓN\",\n",
    "    10: \"ADMINISTRACIÓN\",\n",
    "    11: \"CONTADURÍA\",\n",
    "    12: \"RELACIONES INDUSTRIALES\",\n",
    "    13: \"SOCIOLOGÍA\",\n",
    "    14: \"ECONOMÍA\",\n",
    "    15: \"DERECHO\",\n",
    "    16: \"TEOLOGÍA\"\n",
    "}\n",
    "\n",
    "\n",
    "# Dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar modelo con la misma configuración\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    num_labels=len(index_to_category)\n",
    ")\n",
    "model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Modo inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict carrer\n",
    "\n",
    "def predict_career(text_list, tokenizer, model, max_length=128):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()  # Índices de clase\n",
    "    predicted_labels = [index_to_category[p] for p in preds]\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "def predict_career_top3(text_list, tokenizer, model, index_to_category, \n",
    "                        device, max_length=128, top_k=3, threshold=0.5):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    index_to_category: diccionario {índice: categoría}\n",
    "    device: 'cuda' o 'cpu'\n",
    "    max_length: longitud máxima de tokenización\n",
    "    top_k: número de predicciones (top) a retornar\n",
    "    threshold: umbral mínimo de probabilidad para asignar una clase (vs 'UNKNOWN')\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "\n",
    "        # Convertir logits a probabilidades con softmax\n",
    "        probs = torch.softmax(logits, dim=1)  # [batch_size, num_labels]\n",
    "        \n",
    "        # Obtener los top_k índices y probabilidades\n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "        # top_probs, top_indices => ([batch_size, top_k]), ([batch_size, top_k])\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        # Extraer las k probabilidades e índices para esta fila i\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predicciones: [('FILOSOFÍA', 0.37672391533851624), ('INFORMÁTICA', 0.31185489892959595), ('SOCIOLOGÍA', 0.07941188663244247)]\n"
     ]
    }
   ],
   "source": [
    "# Texto filtrado y concatenado\n",
    "# Texto filtrado y concatenado\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matemática, por ser algo práctico una vez entendías el tema. \n",
    "Sin embargo, también me gustaba la materia de literatura, historia y biología. \n",
    "Educación física, soy mala en los deportes. \n",
    "Si, un curso de inglés, me gusta mucho el idioma. \n",
    "Me gusta ver series y películas, también ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnología, arte y cultura. \n",
    "Acerca de ciencia, como la teoría de la relatividad, cuántica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender cómo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas prácticos y concretos. \n",
    "En un café. \n",
    "Tecnológico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "top3_preds = predict_career_top3(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    "    threshold=0.5\n",
    ")\n",
    "print(\"Top 3 predicciones:\", top3_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\nfrom transformers import pipeline\\n\\n# Cargar el dataset\\ninput_path = \"../data/raw/student_data_extended (2).csv\"  # Reemplaza con la ruta a tu archivo\\noutput_path = \"../data/raw/student_data_extended_process.csv\"  # Ruta para guardar el archivo final\\n\\ndf = pd.read_csv(input_path)\\n\\ncount = 0\\n\\n# Modelos de traducción\\nmodel_name_es_en = \"Helsinki-NLP/opus-mt-es-en\"\\nmodel_name_en_es = \"Helsinki-NLP/opus-mt-en-es\"\\n\\ntranslator_es_en = pipeline(\"translation_es_to_en\", model=model_name_es_en, tokenizer=model_name_es_en)\\ntranslator_en_es = pipeline(\"translation_en_to_es\", model=model_name_en_es, tokenizer=model_name_en_es)\\n\\n# Función de traducción ida y vuelta\\ndef back_translate(text):\\n    # Traducir de español a inglés\\n    translated_to_en = translator_es_en(text, max_length=512, truncation=True)\\n    text_in_english = translated_to_en[0][\\'translation_text\\']\\n\\n    # Traducir de inglés a español\\n    translated_to_es = translator_en_es(text_in_english, max_length=512, truncation=True)\\n    text_in_spanish = translated_to_es[0][\\'translation_text\\']\\n\\n    return text_in_spanish\\n\\n# Crear las columnas `TEXTO` y `CARRERA`\\nprocessed_texts = []\\nprocessed_careers = []\\n\\nfor _, row in df.iterrows():\\n    # Combinar información relevante en una sola oración\\n    texto = f\"estoy interesado en {row[\\'AcademicInterest\\']}. \"             f\"Disfruta de {row[\\'ExtracurricularActivities\\']}. \"             f\"Participo en actividades como {row[\\'ClubMemberships\\']}. \"             f\"Pienso que tengo habilidades en {row[\\'Skills\\']}. \"             f\"Tambien encuentro interes en {row[\\'ResearchInterests\\']}.\"\\n\\n    # Traducir el texto al español usando back-translation\\n    texto_traducido = back_translate(texto)\\n\\n    processed_texts.append(texto_traducido)\\n    processed_careers.append(back_translate(row[\\'AcademicInterest\\']))\\n    \\n    if count == 100:\\n        break\\n    count += 1\\n    print(count)\\n\\n# Crear un nuevo DataFrame\\ndf_processed = pd.DataFrame({\\n    \"TEXTO\": processed_texts,\\n    \"CARRERA\": processed_careers\\n})\\n\\n# Guardar el dataset procesado\\ndf_processed.to_csv(output_path, index=False, encoding=\"utf-8\")\\n\\nprint(f\"Dataset procesado guardado en: {output_path}\")\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el dataset\n",
    "input_path = \"../data/raw/student_data_extended (2).csv\"  # Reemplaza con la ruta a tu archivo\n",
    "output_path = \"../data/raw/student_data_extended_process.csv\"  # Ruta para guardar el archivo final\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Modelos de traducción\n",
    "model_name_es_en = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "model_name_en_es = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "\n",
    "translator_es_en = pipeline(\"translation_es_to_en\", model=model_name_es_en, tokenizer=model_name_es_en)\n",
    "translator_en_es = pipeline(\"translation_en_to_es\", model=model_name_en_es, tokenizer=model_name_en_es)\n",
    "\n",
    "# Función de traducción ida y vuelta\n",
    "def back_translate(text):\n",
    "    # Traducir de español a inglés\n",
    "    translated_to_en = translator_es_en(text, max_length=512, truncation=True)\n",
    "    text_in_english = translated_to_en[0]['translation_text']\n",
    "\n",
    "    # Traducir de inglés a español\n",
    "    translated_to_es = translator_en_es(text_in_english, max_length=512, truncation=True)\n",
    "    text_in_spanish = translated_to_es[0]['translation_text']\n",
    "\n",
    "    return text_in_spanish\n",
    "\n",
    "# Crear las columnas `TEXTO` y `CARRERA`\n",
    "processed_texts = []\n",
    "processed_careers = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Combinar información relevante en una sola oración\n",
    "    texto = f\"estoy interesado en {row['AcademicInterest']}. \" \\\n",
    "            f\"Disfruta de {row['ExtracurricularActivities']}. \" \\\n",
    "            f\"Participo en actividades como {row['ClubMemberships']}. \" \\\n",
    "            f\"Pienso que tengo habilidades en {row['Skills']}. \" \\\n",
    "            f\"Tambien encuentro interes en {row['ResearchInterests']}.\"\n",
    "\n",
    "    # Traducir el texto al español usando back-translation\n",
    "    texto_traducido = back_translate(texto)\n",
    "\n",
    "    processed_texts.append(texto_traducido)\n",
    "    processed_careers.append(back_translate(row['AcademicInterest']))\n",
    "    \n",
    "    if count == 100:\n",
    "        break\n",
    "    count += 1\n",
    "    print(count)\n",
    "\n",
    "# Crear un nuevo DataFrame\n",
    "df_processed = pd.DataFrame({\n",
    "    \"TEXTO\": processed_texts,\n",
    "    \"CARRERA\": processed_careers\n",
    "})\n",
    "\n",
    "# Guardar el dataset procesado\n",
    "df_processed.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Dataset procesado guardado en: {output_path}\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta del estudiante 1\n",
    "user_text1 = \"\"\"Estoy interesado en Ingeniería Industrial. Fui becado y congelé mi carrera en 2020 por temas económicos. Me gustaban las materias de Matemática e Historia de Venezuela. No me agradaban Biología y Física. Me interesa resolver problemas y explorar culturas. Me gustaría ejercer mi carrera en España y viajar por el mundo.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 2\n",
    "user_text2 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Matemáticas y Deportes, eran las que mejores se me daban. No me agradaba Historia porque tengo mala memoria. Me interesa crear, ayudar y resolver problemas. Mi objetivo es conseguir empleo remoto en el extranjero.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 3\n",
    "user_text3 = \"\"\"Estoy interesada en Psicología. Me gustaban Física y Biología porque las entendía. No me agradaban Matemáticas y Castellano porque me parecían tediosas. Me gusta leer, ver películas y bailar. Me interesa crear e investigar. Mi meta es viajar y entender mejor el mundo.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 4\n",
    "user_text4 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaban Matemáticas, Química, Física y Contabilidad porque me gustan las cosas exactas. No me agradaban Dibujo, Historia y Geografía porque había que hacer muchas maquetas. Me gusta liderar, enseñar y resolver problemas. Mi objetivo es trabajar en una oficina.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 5\n",
    "user_text5 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Historia, Física y Química porque se me hacían divertidas. No me agradaba Castellano porque me parece aburrida. Me gusta jugar videojuegos y leer. Me interesa resolver problemas. Mi meta es ganar dinero para ayudar a mis padres.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 6\n",
    "user_text6 = \"\"\"Estoy interesado en Ingeniería en Informática. Me gustaban Matemáticas por sus propiedades y formas interesantes y Química por las reacciones y experimentos. No me agradaba Geografía porque no soy bueno ubicándome. Me gusta crear, liderar, ayudar y resolver problemas. Mi meta es desarrollar videojuegos.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 7\n",
    "user_text7 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaban Matemática y Física porque los números siempre me han llamado la atención. No me agradaba Química porque no entendía nada. Me interesa crear y explorar temas psicológicos y emocionales. Mi objetivo es manejarme bien y cocinar.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 8\n",
    "user_text8 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Matemáticas, Historia y Artes porque me interesan los cálculos, el pasado y el arte. No me agradaban Química y Geografía porque no las entendía bien. Me gusta dibujar, leer manga y jugar videojuegos. Mi meta es crear cómics.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 9\n",
    "user_text9 = \"\"\"Estoy interesada en Relaciones Industriales. Me gustaban Biología y Química porque me agradan sus funciones. No me agradaba Educación Física porque siempre terminaba con dolor de cabeza. Me gusta bailar y explorar culturas. Mi meta es que mi emprendimiento de dulces llegue a más personas.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 10\n",
    "user_text10 = \"\"\"Estoy interesada en Comunicación Social. Me gustaba Biología porque me ayudó a entender procesos humanos. No me agradaba Química porque no tuve un docente permanente. Me interesa ayudar y crear. Mi meta es emprender proyectos propios.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 11\n",
    "user_text11 = \"\"\"Estoy interesado en Comunicación Social. Me gustaban las materias relacionadas con Historia porque investigaba por mi cuenta. No me agradaban las Ciencias porque me costaban bastante. Me gusta leer, editar, y hacer fotografía. Mi meta es crear cosas útiles y vivir de ello.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 12\n",
    "user_text12 = \"\"\"Estoy interesada en Contaduría Pública. Me gustaban Contabilidad y Diseño porque me desenvolvía mejor. No me agradaban Matemática, Historia, Geografía y Política porque no me interesaban. Me gusta hacer ejercicio, pintar y bailar. Mi meta es ser bailarina profesional.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 13\n",
    "user_text13 = \"\"\"Estoy interesada en Educación. Me gustaban Matemática, Química, Biología y Arte porque las entendía bien. No me agradaba Física porque me enredaba en pequeñeces. Me gusta bailar, leer y hornear. Mi meta es abrir una pastelería y presentarme como bailarina profesional.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 14\n",
    "user_text14 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaban Matemáticas y Física porque eran interesantes. No me agradaba Química porque no me llamaba la atención. Me interesa resolver problemas y enseñar. Mi meta es levantar una empresa de desarrollo.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 15\n",
    "user_text15 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaba Computación porque me encantan las computadoras. No me agradaba Castellano porque no me gustan los idiomas. Me gusta leer y jugar videojuegos. Mi meta es tener mi propia oficina con un jardín.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 16\n",
    "user_text16 = \"\"\"Estoy interesado en Ingeniería en Sistemas. Me gustaba Química porque el profesor hacía los temas dinámicos. No me agradaba Historia de Venezuela porque era monótona. Me interesa enseñar y ayudar. Mi meta es aprender alemán y ser políglota.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 17\n",
    "user_text17 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Biología y Psicología porque me gusta entender el comportamiento. No me agradaba Química porque me costaba. Me gusta estar con mis amigos. Mi meta es conseguir estabilidad económica y aprender a tocar la guitarra.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 18\n",
    "user_text18 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaba Matemática porque es práctica y me gustan temas de ciencia. No me agradaba Educación Física porque soy mala en deportes. Me gusta ver series y aprender cosas nuevas. Mi meta es emprender.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 19\n",
    "user_text19 = \"\"\"Estoy interesada en Comunicación Social. Me gustaban Inglés, Biología y Psicología porque me sentía conectada con ellas. No me agradaban Física, Química y Matemática porque me costaba entenderlas. Me gusta investigar y enseñar. Mi meta es fundar una ONG para ayudar a mujeres y niños.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 20\n",
    "user_text20 = \"\"\"Estoy interesado en Física. Me gustaban Matemáticas y Física porque me gustan los cálculos. No me agradaba Dibujo Técnico porque no tenía paciencia. Me interesa crear y resolver problemas. Mi meta es graduarme de la universidad.\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
