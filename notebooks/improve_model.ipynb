{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el entorno y carga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from keybert import KeyBERT\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "# 游늷 Mapea 칤ndice -> categor칤a\n",
    "index_to_category = {\n",
    "    0: \"INDUSTRIAL\", 1: \"CIVIL\", 2: \"INFORM츼TICA\", 3: \"TELECOMUNICACIONES\",\n",
    "    4: \"ARQUITECTURA\", 5: \"FILOSOF칈A\", 6: \"PSICOLOG칈A\", 7: \"LETRAS\",\n",
    "    8: \"COMUNICACI칍N SOCIAL\", 9: \"EDUCACI칍N\", 10: \"ADMINISTRACI칍N\",\n",
    "    11: \"CONTADUR칈A\", 12: \"RELACIONES INDUSTRIALES\", 13: \"SOCIOLOG칈A\",\n",
    "    14: \"ECONOM칈A\", 15: \"DERECHO\", 16: \"TEOLOG칈A\"\n",
    "}\n",
    "\n",
    "# 游늷 Configuraci칩n del dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 游늷 Cargar tokenizer y modelo BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    num_labels=len(index_to_category)\n",
    ")\n",
    "model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Modo inferencia\n",
    "\n",
    "# 游늷 Cargar modelo de KeyBERT\n",
    "kw_model = KeyBERT(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
    "\n",
    "# 游늷 Cargar modelo de SpaCy para espa침ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "stopwords_es = list(nlp.Defaults.stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "####FUNCTIONS FOR TEST PONDERATION\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Si es una lista, unir los elementos en un solo string\n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s치칠칤칩칰침칲]', '', text)  # Eliminar caracteres especiales, pero conservar tildes\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Reemplaza m칰ltiples espacios\n",
    "    \n",
    "    # Procesar el texto con SpaCy sin eliminar todas las stopwords\n",
    "    doc = nlp(text)\n",
    "    cleaned_text = \" \".join([token.text for token in doc if not token.is_punct])\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def extract_keywords(text, top_k=10):\n",
    "    \"\"\"\n",
    "    Extrae palabras clave utilizando KeyBERT y TF-IDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"el top k es \", top_k)\n",
    "    clean_text = preprocess_text(text)\n",
    "    keybert_keywords = kw_model.extract_keywords(clean_text, keyphrase_ngram_range=(1, 1), stop_words=stopwords_es, top_n=top_k)\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords_es)\n",
    "    tfidf_scores = vectorizer.fit_transform([clean_text]).toarray().flatten()\n",
    "    tfidf_tokens = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Crear un diccionario para mantener el score m치s alto para cada palabra\n",
    "    keyword_scores = {}\n",
    "    \n",
    "    # Agregar scores de KeyBERT\n",
    "    for word, score in keybert_keywords:\n",
    "        keyword_scores[word] = score\n",
    "        \n",
    "    # # Agregar o actualizar con scores de TF-IDF\n",
    "    # for idx, token in enumerate(tfidf_tokens):\n",
    "    #     if token in keyword_scores:\n",
    "    #         keyword_scores[token] = max(keyword_scores[token], tfidf_scores[idx])\n",
    "    #     else:\n",
    "    #         keyword_scores[token] = tfidf_scores[idx]\n",
    "            \n",
    "    # Agregar/actualizar con scores de TF-IDF\n",
    "    for idx, token in enumerate(tfidf_tokens):\n",
    "        normal_token = token.strip().lower()\n",
    "        if normal_token in keyword_scores:\n",
    "            # Mantenemos el score m치ximo\n",
    "            keyword_scores[normal_token] = max(keyword_scores[normal_token], tfidf_scores[idx])\n",
    "        else:\n",
    "            keyword_scores[normal_token] = tfidf_scores[idx]\n",
    "\n",
    "    # Ordenar por score y tomar los top_k 칰nicos\n",
    "    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    unique_keywords = []\n",
    "    seen_words = set()\n",
    "\n",
    "    for word, score in sorted_keywords:\n",
    "        # 'word' ya est치 normalizada (sin espacios ni may칰sculas)\n",
    "        if word not in seen_words:\n",
    "            seen_words.add(word)\n",
    "            unique_keywords.append((word, score))\n",
    "            if len(unique_keywords) == top_k:\n",
    "                break\n",
    "\n",
    "    print(\"unique keywords\", unique_keywords)\n",
    "    return unique_keywords\n",
    "\n",
    "def predict_career_with_keywords(text, tokenizer, model, index_to_category, device, max_length=512, top_k=15, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Preprocesa el texto, extrae palabras clave y realiza la predicci칩n de carreras.\n",
    "    \"\"\"\n",
    "    print(\"ENTRANDO A KEYBERT \", text)\n",
    "    keywords = extract_keywords(text, top_k=20)\n",
    "    extracted_keywords = \" \".join([word for word, _ in keywords])\n",
    "    print(\"ENTRANDO A KEYBERT \")\n",
    "    # 游댳 Concatenar palabras clave al texto original\n",
    "    enriched_text = f\"{text} {extracted_keywords}\"\n",
    "    print(enriched_text)\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        [enriched_text],  \n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        scaled_logits = logits / temperature\n",
    "        probs = torch.softmax(scaled_logits, dim=1)\n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len([text])):\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游댳 Palabras clave detectadas: con KEYBERT [('biolog칤a educaci칩n', 0.6218), ('pr치cticos concretos', 0.5893), ('relatividad cu치ntica', 0.5863), ('gustaba matem치tica', 0.5696), ('matem치tica pr치ctico', 0.5915), ('cosas prefiero', 0.5629), ('pr치ctico entend칤as', 0.6024), ('ciencia tecnolog칤a', 0.59), ('historia cultura', 0.58), ('teor칤a relatividad', 0.5743), ('utilizarlos aplicaciones', 0.6088), ('tecnol칩gico emprender', 0.5693), ('cultura acerca', 0.5718), ('modelos utilizarlos', 0.607), ('historia biolog칤a', 0.6054)]\n",
      "Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
      "Me gustaba mucho la parte matem치tica, por ser algo pr치ctico una vez entend칤as el tema. \n",
      "Sin embargo, tambi칠n me gustaba la materia de literatura, historia y biolog칤a. \n",
      "Educaci칩n f칤sica, soy mala en los deportes. \n",
      "Si, un curso de ingl칠s, me gusta mucho el idioma. \n",
      "Me gusta ver series y pel칤culas, tambi칠n ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
      "Ciencia, tecnolog칤a, arte y cultura. \n",
      "Acerca de ciencia, como la teor칤a de la relatividad, cu치ntica, me gusta mucho entender el mundo desde esa perspectiva. \n",
      "Crear, investigar y resolver problemas. \n",
      "Me interesa entender c칩mo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas pr치cticos y concretos. \n",
      "En un caf칠. \n",
      "Tecnol칩gico. \n",
      "Emprender. mala deportes pel칤culas documentales cultura acerca modelos utilizarlos entend칤as tema cosas prefiero ciencia tecnolog칤a teor칤a relatividad educaci칩n f칤sica utilizarlos aplicaciones tecnol칩gico emprender pr치ctico entend칤as relatividad cu치ntica historia biolog칤a pr치cticos concretos gustaba matem치tica matem치tica pr치ctico desarrollador ia biolog칤a educaci칩n historia cultura\n",
      "游댳 Texto Original:\n",
      "Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
      "Me gustaba mucho la parte matem치tica, por ser algo pr치ctico una vez entend칤as el tema. \n",
      "Sin embargo, tambi칠n me gustaba la materia de literatura, historia y biolog칤a. \n",
      "Educaci칩n f칤sica, soy mala en los deportes. \n",
      "Si, un curso de ingl칠s, me gusta mucho el idioma. \n",
      "Me gusta ver series y pel칤culas, tambi칠n ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
      "Ciencia, tecnolog칤a, arte y cultura. \n",
      "Acerca de ciencia, como la teor칤a de la relatividad, cu치ntica, me gusta mucho entender el mundo desde esa perspectiva. \n",
      "Crear, investigar y resolver problemas. \n",
      "Me interesa entender c칩mo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas pr치cticos y concretos. \n",
      "En un caf칠. \n",
      "Tecnol칩gico. \n",
      "Emprender.\n",
      "\n",
      "游댳 Palabras Clave Detectadas:\n",
      "[('biolog칤a educaci칩n', 0.6218), ('pr치cticos concretos', 0.5893), ('relatividad cu치ntica', 0.5863), ('gustaba matem치tica', 0.5696), ('matem치tica pr치ctico', 0.5915), ('cosas prefiero', 0.5629), ('pr치ctico entend칤as', 0.6024), ('ciencia tecnolog칤a', 0.59), ('historia cultura', 0.58), ('teor칤a relatividad', 0.5743), ('utilizarlos aplicaciones', 0.6088), ('tecnol칩gico emprender', 0.5693), ('cultura acerca', 0.5718), ('modelos utilizarlos', 0.607), ('historia biolog칤a', 0.6054)]\n",
      "\n",
      "游댳 Predicciones Mejoradas:\n",
      "INFORM츼TICA: 51.09%\n",
      "FILOSOF칈A: 10.86%\n",
      "SOCIOLOG칈A: 6.11%\n"
     ]
    }
   ],
   "source": [
    "## PRUEBA DE LA FUNCION DE PONDERACION CON EL MODELO KEYBERT \n",
    "\n",
    "# Texto filtrado y concatenado\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matem치tica, por ser algo pr치ctico una vez entend칤as el tema. \n",
    "Sin embargo, tambi칠n me gustaba la materia de literatura, historia y biolog칤a. \n",
    "Educaci칩n f칤sica, soy mala en los deportes. \n",
    "Si, un curso de ingl칠s, me gusta mucho el idioma. \n",
    "Me gusta ver series y pel칤culas, tambi칠n ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnolog칤a, arte y cultura. \n",
    "Acerca de ciencia, como la teor칤a de la relatividad, cu치ntica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender c칩mo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas pr치cticos y concretos. \n",
    "En un caf칠. \n",
    "Tecnol칩gico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "#user_text = \"\"\"Desde muy joven, he sentido una gran pasi칩n por la tecnolog칤a. Me encanta aprender y desarrollar soluciones de software que resuelvan problemas reales; por ello, he orientado mis estudios hacia la Ingenier칤a Inform치tica. Adem치s, me fascina el mundo de las telecomunicaciones, ya que creo que conectar a las personas a trav칠s de redes modernas y eficientes es clave para el avance social y econ칩mico. Por otro lado, tambi칠n me interesa la parte gerencial y organizativa, lo que me lleva a valorar la Administraci칩n; considero esencial saber planificar, gestionar proyectos y liderar equipos para llevar adelante iniciativas tecnol칩gicas. En resumen, mi formaci칩n y mis intereses se centran en el desarrollo de sistemas inform치ticos, la conectividad a trav칠s de telecomunicaciones y la gesti칩n estrat칠gica en entornos empresariales.\"\"\"\n",
    "#user_text = \"\"\"Estoy interesado en Ingenier칤a Industrial. Fui becado y congel칠 mi carrera en 2020 por temas econ칩micos. Me gustaban las materias de Matem치tica e Historia de Venezuela. No me agradaban Biolog칤a y F칤sica. Me interesa resolver problemas y explorar culturas. Me gustar칤a ejercer mi carrera en Espa침a y viajar por el mundo.\"\"\"\n",
    "# user_text = \"Me interesa trabajar con computadoras y desarrollar aplicaciones de software.\"\n",
    "\n",
    "\n",
    "# 游댳 Prueba con el texto deusuario (PRUEBA KEYBERT)\n",
    "keywords = extract_keywords(user_text, top_k=15)\n",
    "print(\"游댳 Palabras clave detectadas: con KEYBERT\", keywords)\n",
    "\n",
    "\n",
    "\n",
    "# 游댳 Realizar predicci칩n con palabras clave a침adidas\n",
    "predictions = predict_career_with_keywords(\n",
    "    text=user_text,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    temperature=1.3,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "print(\"游댳 Texto Original:\")\n",
    "print(user_text)\n",
    "print(\"\\n游댳 Palabras Clave Detectadas:\")\n",
    "print(extract_keywords(user_text, top_k=15))\n",
    "print(\"\\n游댳 Predicciones Mejoradas:\")\n",
    "for career, prob in predictions[0]:\n",
    "    print(f\"{career}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original:\n",
      "Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
      "Me gustaba mucho la parte matem치tica, por ser algo pr치ctico una vez entend칤as el tema. \n",
      "Sin embargo, tambi칠n me gustaba la materia de literatura, historia y biolog칤a. \n",
      "Educaci칩n f칤sica, soy mala en los deportes. \n",
      "Si, un curso de ingl칠s, me gusta mucho el idioma. \n",
      "Me gusta ver series y pel칤culas, tambi칠n ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
      "Ciencia, tecnolog칤a, arte y cultura. \n",
      "Acerca de ciencia, como la teor칤a de la relatividad, cu치ntica, me gusta mucho entender el mundo desde esa perspectiva. \n",
      "Crear, investigar y resolver problemas. \n",
      "Me interesa entender c칩mo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas pr치cticos y concretos. \n",
      "En un caf칠. \n",
      "Tecnol칩gico. \n",
      "Emprender.\n",
      "\n",
      "Texto preprocesado:\n",
      "como desarrollador de ia creo modelos para luego utilizarlos en aplicaciones me gustaba mucho la parte matem치tica por ser algo pr치ctico una vez entend칤as el tema sin embargo tambi칠n me gustaba la materia de literatura historia y biolog칤a educaci칩n f칤sica soy mala en los deportes si un curso de ingl칠s me gusta mucho el idioma me gusta ver series y pel칤culas tambi칠n ver documentales o videos para aprender cosas nuevas de ciencia historia cultura general ciencia tecnolog칤a arte y cultura acerca de ciencia como la teor칤a de la relatividad cu치ntica me gusta mucho entender el mundo desde esa perspectiva crear investigar y resolver problemas me interesa entender c칩mo funciona el mundo me gusta imaginar y crear cosas nuevas prefiero resolver problemas pr치cticos y concretos en un caf칠 tecnol칩gico emprender\n",
      "\n",
      "Predicciones:\n",
      "INFORM츼TICA: 38.56%\n",
      "FILOSOF칈A: 23.21%\n",
      "LETRAS: 5.74%\n"
     ]
    }
   ],
   "source": [
    "# // ... existing code ...\n",
    "\n",
    "\n",
    "# Cargar el modelo de SpaCy para espa침ol\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def predict_career_with_preprocessing(text_list: list, tokenizer, model, \n",
    "                                   index_to_category: dict, device: str,\n",
    "                                   max_length: int = 128, top_k: int = 3, temperature: float = 1.0) -> list:\n",
    "    \"\"\"\n",
    "    Preprocesa el texto y realiza la predicci칩n de carreras.\n",
    "    \n",
    "    Args:\n",
    "        text_list (list): Lista de textos a procesar\n",
    "        tokenizer: Tokenizer de BERT\n",
    "        model: Modelo BERT entrenado\n",
    "        index_to_category (dict): Mapeo de 칤ndices a nombres de carreras\n",
    "        device (str): Dispositivo para procesamiento ('cuda' o 'cpu')\n",
    "        max_length (int): Longitud m치xima de tokens\n",
    "        top_k (int): N칰mero de predicciones top a retornar\n",
    "        \n",
    "    Returns:\n",
    "        list: Lista de tuplas (carrera, probabilidad) para cada texto\n",
    "    \"\"\"\n",
    "    # Preprocesar cada texto\n",
    "    processed_texts = [preprocess_text(text) for text in text_list]\n",
    "    \n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        processed_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Aplicar temperatura para suavizar las probabilidades\n",
    "        scaled_logits = logits / temperature\n",
    "        probs = torch.softmax(scaled_logits, dim=1)\n",
    "        \n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "# Ejemplo de uso:\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matem치tica, por ser algo pr치ctico una vez entend칤as el tema. \n",
    "Sin embargo, tambi칠n me gustaba la materia de literatura, historia y biolog칤a. \n",
    "Educaci칩n f칤sica, soy mala en los deportes. \n",
    "Si, un curso de ingl칠s, me gusta mucho el idioma. \n",
    "Me gusta ver series y pel칤culas, tambi칠n ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnolog칤a, arte y cultura. \n",
    "Acerca de ciencia, como la teor칤a de la relatividad, cu치ntica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender c칩mo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas pr치cticos y concretos. \n",
    "En un caf칠. \n",
    "Tecnol칩gico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "# user_text = \"\"\"Desde muy joven, he sentido una gran pasi칩n por la tecnolog칤a. Me encanta aprender y desarrollar soluciones de software que resuelvan problemas reales; por ello, he orientado mis estudios hacia la Ingenier칤a Inform치tica. Adem치s, me fascina el mundo de las telecomunicaciones, ya que creo que conectar a las personas a trav칠s de redes modernas y eficientes es clave para el avance social y econ칩mico. Por otro lado, tambi칠n me interesa la parte gerencial y organizativa, lo que me lleva a valorar la Administraci칩n; considero esencial saber planificar, gestionar proyectos y liderar equipos para llevar adelante iniciativas tecnol칩gicas. En resumen, mi formaci칩n y mis intereses se centran en el desarrollo de sistemas inform치ticos, la conectividad a trav칠s de telecomunicaciones y la gesti칩n estrat칠gica en entornos empresariales.\"\"\"\n",
    "\n",
    "#user_text = \"\"\"Estoy interesado en Ingenier칤a Industrial. Fui becado y congel칠 mi carrera en 2020 por temas econ칩micos. Me gustaban las materias de Matem치tica e Historia de Venezuela. No me agradaban Biolog칤a y F칤sica. Me interesa resolver problemas y explorar culturas. Me gustar칤a ejercer mi carrera en Espa침a y viajar por el mundo.\"\"\"\n",
    "\n",
    "# Realizar predicci칩n con el texto preprocesado\n",
    "predictions = predict_career_with_preprocessing(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    temperature=1.3,\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "print(\"Texto original:\")\n",
    "print(user_text)\n",
    "print(\"\\nTexto preprocesado:\")\n",
    "print(preprocess_text(user_text))\n",
    "print(\"\\nPredicciones:\")\n",
    "for career, prob in predictions[0]:\n",
    "    print(f\"{career}: {prob:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
