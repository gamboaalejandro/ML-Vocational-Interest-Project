{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el entorno y carga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_31208\\207714581.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Mapea índice -> categoría (lo que usaste en training)\n",
    "index_to_category = {\n",
    "    0: \"INDUSTRIAL\", \n",
    "    1: \"CIVIL\", \n",
    "    2: \"INFORMÁTICA\",\n",
    "    3: \"TELECOMUNICACIONES\",\n",
    "    4: \"ARQUITECTURA\",\n",
    "    5: \"FILOSOFÍA\",\n",
    "    6: \"PSICOLOGÍA\",\n",
    "    7: \"LETRAS\",\n",
    "    8: \"COMUNICACIÓN SOCIAL\",\n",
    "    9: \"EDUCACIÓN\",\n",
    "    10: \"ADMINISTRACIÓN\",\n",
    "    11: \"CONTADURÍA\",\n",
    "    12: \"RELACIONES INDUSTRIALES\",\n",
    "    13: \"SOCIOLOGÍA\",\n",
    "    14: \"ECONOMÍA\",\n",
    "    15: \"DERECHO\",\n",
    "    16: \"TEOLOGÍA\"\n",
    "}\n",
    "\n",
    "\n",
    "# Dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar modelo con la misma configuración\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    num_labels=len(index_to_category)\n",
    ")\n",
    "model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Modo inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict carrer\n",
    "\n",
    "def predict_career(text_list, tokenizer, model, max_length=128):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()  # Índices de clase\n",
    "    predicted_labels = [index_to_category[p] for p in preds]\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict_career_top3(text_list, tokenizer, model, index_to_category, \n",
    "                        device, max_length=128, top_k=3, threshold=0.5):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    index_to_category: diccionario {índice: categoría}\n",
    "    device: 'cuda' o 'cpu'\n",
    "    max_length: longitud máxima de tokenización\n",
    "    top_k: número de predicciones (top) a retornar\n",
    "    threshold: umbral mínimo de probabilidad para asignar una clase (vs 'UNKNOWN')\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "\n",
    "        # Convertir logits a probabilidades con softmax\n",
    "        probs = torch.softmax(logits, dim=1)  # [batch_size, num_labels]\n",
    "        \n",
    "        # Obtener los top_k índices y probabilidades\n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "        # top_probs, top_indices => ([batch_size, top_k]), ([batch_size, top_k])\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        # Extraer las k probabilidades e índices para esta fila i\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predicciones: [('COMUNICACIÓN SOCIAL', 0.7758367657661438), ('SOCIOLOGÍA', 0.06521878391504288), ('LETRAS', 0.053958047181367874)]\n"
     ]
    }
   ],
   "source": [
    "# Texto filtrado y concatenado\n",
    "user_text = \"\"\"\n",
    "Me gustan el inglés, biología y psicología porque me sentía conectada con esas materias. \n",
    "Por el contrario, física, química y matemática se me hicieron difíciles. \n",
    "He realizado cursos de fotografía, oratoria y modelos de naciones unidas.\n",
    "\n",
    "Disfruto correr, pintar, dormir, pasear y ver películas. Me interesan la cultura, el arte, los derechos humanos y los temas sociales. \n",
    "Aprendería más sobre periodismo de investigación y documentación, porque considero fundamental contar aquello que se mantiene oculto. \n",
    "Me motiva investigar, ayudar y enseñar.\n",
    "\n",
    "Me interesa entender cómo funciona el mundo, prefiero resolver problemas prácticos y concretos, \n",
    "disfruto trabajar con personas y ayudarlas, y me apasiona explorar culturas, ideas o filosofías. \n",
    "Visualizo un estudio creativo o colaborar con una ONG que promueva proyectos sociales.\n",
    "\n",
    "Mi meta es terminar mis dos carreras y fundar una ONG que ayude y enseñe a mujeres y niños en situaciones complejas.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "top3_preds = predict_career_top3(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    "    threshold=0.5\n",
    ")\n",
    "print(\"Top 3 predicciones:\", top3_preds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
