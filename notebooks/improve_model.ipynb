{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el entorno y carga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_16832\\718828362.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Mapea índice -> categoría (lo que usaste en training)\n",
    "index_to_category = {\n",
    "    0: \"INDUSTRIAL\", \n",
    "    1: \"CIVIL\", \n",
    "    2: \"INFORMÁTICA\",\n",
    "    3: \"TELECOMUNICACIONES\",\n",
    "    4: \"ARQUITECTURA\",\n",
    "    5: \"FILOSOFÍA\",\n",
    "    6: \"PSICOLOGÍA\",\n",
    "    7: \"LETRAS\",\n",
    "    8: \"COMUNICACIÓN SOCIAL\",\n",
    "    9: \"EDUCACIÓN\",\n",
    "    10: \"ADMINISTRACIÓN\",\n",
    "    11: \"CONTADURÍA\",\n",
    "    12: \"RELACIONES INDUSTRIALES\",\n",
    "    13: \"SOCIOLOGÍA\",\n",
    "    14: \"ECONOMÍA\",\n",
    "    15: \"DERECHO\",\n",
    "    16: \"TEOLOGÍA\"\n",
    "}\n",
    "\n",
    "\n",
    "# Dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar modelo con la misma configuración\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    num_labels=17\n",
    ")\n",
    "model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Modo inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict carrer\n",
    "\n",
    "def predict_career(text_list, tokenizer, model, max_length=128):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()  # Índices de clase\n",
    "    predicted_labels = [index_to_category[p] for p in preds]\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "def predict_career_top3(text_list, tokenizer, model, index_to_category, \n",
    "                        device, max_length=128, top_k=3, threshold=0.5):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    index_to_category: diccionario {índice: categoría}\n",
    "    device: 'cuda' o 'cpu'\n",
    "    max_length: longitud máxima de tokenización\n",
    "    top_k: número de predicciones (top) a retornar\n",
    "    threshold: umbral mínimo de probabilidad para asignar una clase (vs 'UNKNOWN')\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "\n",
    "        # Convertir logits a probabilidades con softmax\n",
    "        probs = torch.softmax(logits, dim=1)  # [batch_size, num_labels]\n",
    "        \n",
    "        # Obtener los top_k índices y probabilidades\n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "        # top_probs, top_indices => ([batch_size, top_k]), ([batch_size, top_k])\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        # Extraer las k probabilidades e índices para esta fila i\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 predicciones: [('FILOSOFÍA', 0.272817999124527), ('SOCIOLOGÍA', 0.11937537044286728), ('ECONOMÍA', 0.10283531993627548)]\n"
     ]
    }
   ],
   "source": [
    "# Texto filtrado y concatenado\n",
    "# Texto filtrado y concatenado\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matemática, por ser algo práctico una vez entendías el tema. \n",
    "Sin embargo, también me gustaba la materia de literatura, historia y biología. \n",
    "Educación física, soy mala en los deportes. \n",
    "Si, un curso de inglés, me gusta mucho el idioma. \n",
    "Me gusta ver series y películas, también ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnología, arte y cultura. \n",
    "Acerca de ciencia, como la teoría de la relatividad, cuántica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender cómo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas prácticos y concretos. \n",
    "En un café. \n",
    "Tecnológico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "user_text = \"\"\"Desde muy joven, he sentido una gran pasión por la tecnología. Me encanta aprender y desarrollar soluciones de software que resuelvan problemas reales; por ello, he orientado mis estudios hacia la Ingeniería Informática. Además, me fascina el mundo de las telecomunicaciones, ya que creo que conectar a las personas a través de redes modernas y eficientes es clave para el avance social y económico. Por otro lado, también me interesa la parte gerencial y organizativa, lo que me lleva a valorar la Administración; considero esencial saber planificar, gestionar proyectos y liderar equipos para llevar adelante iniciativas tecnológicas. En resumen, mi formación y mis intereses se centran en el desarrollo de sistemas informáticos, la conectividad a través de telecomunicaciones y la gestión estratégica en entornos empresariales.\"\"\"\n",
    "user_text = \"\"\"Estoy interesado en Ingeniería Industrial. Fui becado y congelé mi carrera en 2020 por temas económicos. Me gustaban las materias de Matemática e Historia de Venezuela. No me agradaban Biología y Física. Me interesa resolver problemas y explorar culturas. Me gustaría ejercer mi carrera en España y viajar por el mundo.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "top3_preds = predict_career_top3(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    "    threshold=0.5\n",
    ")\n",
    "print(\"Top 3 predicciones:\", top3_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Respuesta del estudiante 1\n",
    "user_text1 = \"\"\"Estoy interesado en Ingeniería Industrial. Fui becado y congelé mi carrera en 2020 por temas económicos. Me gustaban las materias de Matemática e Historia de Venezuela. No me agradaban Biología y Física. Me interesa resolver problemas y explorar culturas. Me gustaría ejercer mi carrera en España y viajar por el mundo.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 2\n",
    "user_text2 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Matemáticas y Deportes, eran las que mejores se me daban. No me agradaba Historia porque tengo mala memoria. Me interesa crear, ayudar y resolver problemas. Mi objetivo es conseguir empleo remoto en el extranjero.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 3\n",
    "user_text3 = \"\"\"Estoy interesada en Psicología. Me gustaban Física y Biología porque las entendía. No me agradaban Matemáticas y Castellano porque me parecían tediosas. Me gusta leer, ver películas y bailar. Me interesa crear e investigar. Mi meta es viajar y entender mejor el mundo.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 4\n",
    "user_text4 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaban Matemáticas, Química, Física y Contabilidad porque me gustan las cosas exactas. No me agradaban Dibujo, Historia y Geografía porque había que hacer muchas maquetas. Me gusta liderar, enseñar y resolver problemas. Mi objetivo es trabajar en una oficina.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 5\n",
    "user_text5 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Historia, Física y Química porque se me hacían divertidas. No me agradaba Castellano porque me parece aburrida. Me gusta jugar videojuegos y leer. Me interesa resolver problemas. Mi meta es ganar dinero para ayudar a mis padres.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 6\n",
    "user_text6 = \"\"\"Estoy interesado en Ingeniería en Informática. Me gustaban Matemáticas por sus propiedades y formas interesantes y Química por las reacciones y experimentos. No me agradaba Geografía porque no soy bueno ubicándome. Me gusta crear, liderar, ayudar y resolver problemas. Mi meta es desarrollar videojuegos.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 7\n",
    "user_text7 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaban Matemática y Física porque los números siempre me han llamado la atención. No me agradaba Química porque no entendía nada. Me interesa crear y explorar temas psicológicos y emocionales. Mi objetivo es manejarme bien y cocinar.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 8\n",
    "user_text8 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Matemáticas, Historia y Artes porque me interesan los cálculos, el pasado y el arte. No me agradaban Química y Geografía porque no las entendía bien. Me gusta dibujar, leer manga y jugar videojuegos. Mi meta es crear cómics.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 9\n",
    "user_text9 = \"\"\"Estoy interesada en Relaciones Industriales. Me gustaban Biología y Química porque me agradan sus funciones. No me agradaba Educación Física porque siempre terminaba con dolor de cabeza. Me gusta bailar y explorar culturas. Mi meta es que mi emprendimiento de dulces llegue a más personas.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 10\n",
    "user_text10 = \"\"\"Estoy interesada en Comunicación Social. Me gustaba Biología porque me ayudó a entender procesos humanos. No me agradaba Química porque no tuve un docente permanente. Me interesa ayudar y crear. Mi meta es emprender proyectos propios.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 11\n",
    "user_text11 = \"\"\"Estoy interesado en Comunicación Social. Me gustaban las materias relacionadas con Historia porque investigaba por mi cuenta. No me agradaban las Ciencias porque me costaban bastante. Me gusta leer, editar, y hacer fotografía. Mi meta es crear cosas útiles y vivir de ello.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 12\n",
    "user_text12 = \"\"\"Estoy interesada en Contaduría Pública. Me gustaban Contabilidad y Diseño porque me desenvolvía mejor. No me agradaban Matemática, Historia, Geografía y Política porque no me interesaban. Me gusta hacer ejercicio, pintar y bailar. Mi meta es ser bailarina profesional.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 13\n",
    "user_text13 = \"\"\"Estoy interesada en Educación. Me gustaban Matemática, Química, Biología y Arte porque las entendía bien. No me agradaba Física porque me enredaba en pequeñeces. Me gusta bailar, leer y hornear. Mi meta es abrir una pastelería y presentarme como bailarina profesional.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 14\n",
    "user_text14 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaban Matemáticas y Física porque eran interesantes. No me agradaba Química porque no me llamaba la atención. Me interesa resolver problemas y enseñar. Mi meta es levantar una empresa de desarrollo.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 15\n",
    "user_text15 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaba Computación porque me encantan las computadoras. No me agradaba Castellano porque no me gustan los idiomas. Me gusta leer y jugar videojuegos. Mi meta es tener mi propia oficina con un jardín.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 16\n",
    "user_text16 = \"\"\"Estoy interesado en Ingeniería en Sistemas. Me gustaba Química porque el profesor hacía los temas dinámicos. No me agradaba Historia de Venezuela porque era monótona. Me interesa enseñar y ayudar. Mi meta es aprender alemán y ser políglota.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 17\n",
    "user_text17 = \"\"\"Estoy interesado en Ingeniería Informática. Me gustaban Biología y Psicología porque me gusta entender el comportamiento. No me agradaba Química porque me costaba. Me gusta estar con mis amigos. Mi meta es conseguir estabilidad económica y aprender a tocar la guitarra.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 18\n",
    "user_text18 = \"\"\"Estoy interesada en Ingeniería Informática. Me gustaba Matemática porque es práctica y me gustan temas de ciencia. No me agradaba Educación Física porque soy mala en deportes. Me gusta ver series y aprender cosas nuevas. Mi meta es emprender.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 19\n",
    "user_text19 = \"\"\"Estoy interesada en Comunicación Social. Me gustaban Inglés, Biología y Psicología porque me sentía conectada con ellas. No me agradaban Física, Química y Matemática porque me costaba entenderlas. Me gusta investigar y enseñar. Mi meta es fundar una ONG para ayudar a mujeres y niños.\"\"\"\n",
    "\n",
    "# Respuesta del estudiante 20\n",
    "user_text20 = \"\"\"Estoy interesado en Física. Me gustaban Matemáticas y Física porque me gustan los cálculos. No me agradaba Dibujo Técnico porque no tenía paciencia. Me interesa crear y resolver problemas. Mi meta es graduarme de la universidad.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original:\n",
      "Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
      "Me gustaba mucho la parte matemática, por ser algo práctico una vez entendías el tema. \n",
      "Sin embargo, también me gustaba la materia de literatura, historia y biología. \n",
      "Educación física, soy mala en los deportes. \n",
      "Si, un curso de inglés, me gusta mucho el idioma. \n",
      "Me gusta ver series y películas, también ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
      "Ciencia, tecnología, arte y cultura. \n",
      "Acerca de ciencia, como la teoría de la relatividad, cuántica, me gusta mucho entender el mundo desde esa perspectiva. \n",
      "Crear, investigar y resolver problemas. \n",
      "Me interesa entender cómo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas prácticos y concretos. \n",
      "En un café. \n",
      "Tecnológico. \n",
      "Emprender.\n",
      "\n",
      "Texto preprocesado:\n",
      "desarrollador ia modelo utilizar él aplicación gustar matemático práctico entendía tema gustar materia literatura historio biología educación físico malo deporte curso inglés gustar idioma gustar serie película documental video aprender cosa ciencia historio cultura general ciencia tecnologío arte cultura acerca ciencia teoría relatividad cuántico gustar entender mundo perspectiva crear investigar resolver problema interesar entender funcionar mundo gustar imaginar crear cosa preferir resolver problema práctico concreto café tecnológico emprender\n",
      "\n",
      "Predicciones:\n",
      "SOCIOLOGÍA: 57.83%\n",
      "FILOSOFÍA: 5.07%\n",
      "ADMINISTRACIÓN: 4.77%\n"
     ]
    }
   ],
   "source": [
    "# // ... existing code ...\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Cargar el modelo de SpaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesa el texto aplicando los siguientes pasos:\n",
    "    1. Convierte a minúsculas\n",
    "    2. Elimina caracteres especiales manteniendo acentos\n",
    "    3. Elimina espacios extra\n",
    "    4. Elimina stopwords\n",
    "    5. Aplica lematización\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto a preprocesar\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto preprocesado\n",
    "    \"\"\"\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminar caracteres especiales pero mantener acentos\n",
    "    text = re.sub(r'[^a-záéíóúñü\\s]', '', text)\n",
    "    \n",
    "    # Reemplazar múltiples espacios por uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Procesar con SpaCy para lematización y eliminación de stopwords\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Unir los lemas de las palabras que no son stopwords ni puntuación\n",
    "    cleaned_text = \" \".join([token.text for token in doc if not token.is_punct])  # No eliminar stopwords ni lematizar todo\n",
    "\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def predict_career_with_preprocessing(text_list: list, tokenizer, model, \n",
    "                                   index_to_category: dict, device: str,\n",
    "                                   max_length: int = 128, top_k: int = 3, temperature: float = 1.5) -> list:\n",
    "    \"\"\"\n",
    "    Preprocesa el texto y realiza la predicción de carreras.\n",
    "    \n",
    "    Args:\n",
    "        text_list (list): Lista de textos a procesar\n",
    "        tokenizer: Tokenizer de BERT\n",
    "        model: Modelo BERT entrenado\n",
    "        index_to_category (dict): Mapeo de índices a nombres de carreras\n",
    "        device (str): Dispositivo para procesamiento ('cuda' o 'cpu')\n",
    "        max_length (int): Longitud máxima de tokens\n",
    "        top_k (int): Número de predicciones top a retornar\n",
    "        \n",
    "    Returns:\n",
    "        list: Lista de tuplas (carrera, probabilidad) para cada texto\n",
    "    \"\"\"\n",
    "    # Preprocesar cada texto\n",
    "    processed_texts = [preprocess_text(text) for text in text_list]\n",
    "    \n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        processed_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Aplicar temperatura para suavizar las probabilidades\n",
    "        scaled_logits = logits / temperature\n",
    "        probs = torch.softmax(scaled_logits, dim=1)\n",
    "        \n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "# Ejemplo de uso:\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matemática, por ser algo práctico una vez entendías el tema. \n",
    "Sin embargo, también me gustaba la materia de literatura, historia y biología. \n",
    "Educación física, soy mala en los deportes. \n",
    "Si, un curso de inglés, me gusta mucho el idioma. \n",
    "Me gusta ver series y películas, también ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnología, arte y cultura. \n",
    "Acerca de ciencia, como la teoría de la relatividad, cuántica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender cómo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas prácticos y concretos. \n",
    "En un café. \n",
    "Tecnológico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "# user_text = \"\"\"Desde muy joven, he sentido una gran pasión por la tecnología. Me encanta aprender y desarrollar soluciones de software que resuelvan problemas reales; por ello, he orientado mis estudios hacia la Ingeniería Informática. Además, me fascina el mundo de las telecomunicaciones, ya que creo que conectar a las personas a través de redes modernas y eficientes es clave para el avance social y económico. Por otro lado, también me interesa la parte gerencial y organizativa, lo que me lleva a valorar la Administración; considero esencial saber planificar, gestionar proyectos y liderar equipos para llevar adelante iniciativas tecnológicas. En resumen, mi formación y mis intereses se centran en el desarrollo de sistemas informáticos, la conectividad a través de telecomunicaciones y la gestión estratégica en entornos empresariales.\"\"\"\n",
    "\n",
    "#user_text = \"\"\"Estoy interesado en Ingeniería Industrial. Fui becado y congelé mi carrera en 2020 por temas económicos. Me gustaban las materias de Matemática e Historia de Venezuela. No me agradaban Biología y Física. Me interesa resolver problemas y explorar culturas. Me gustaría ejercer mi carrera en España y viajar por el mundo.\"\"\"\n",
    "\n",
    "# Realizar predicción con el texto preprocesado\n",
    "predictions = predict_career_with_preprocessing(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "print(\"Texto original:\")\n",
    "print(user_text)\n",
    "print(\"\\nTexto preprocesado:\")\n",
    "print(preprocess_text(user_text))\n",
    "print(\"\\nPredicciones:\")\n",
    "for career, prob in predictions[0]:\n",
    "    print(f\"{career}: {prob:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
