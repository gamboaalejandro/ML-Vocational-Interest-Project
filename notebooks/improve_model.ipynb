{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el entorno y carga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Mapea índice -> categoría (lo que usaste en training)\n",
    "index_to_category = {\n",
    "    0: \"INDUSTRIAL\", \n",
    "    1: \"CIVIL\", \n",
    "    2: \"INFORMÁTICA\",\n",
    "    3: \"TELECOMUNICACIONES\",\n",
    "    4: \"ARQUITECTURA\",\n",
    "    5: \"FILOSOFÍA\",\n",
    "    6: \"PSICOLOGÍA\",\n",
    "    7: \"LETRAS\",\n",
    "    8: \"COMUNICACIÓN SOCIAL\",\n",
    "    9: \"EDUCACIÓN\",\n",
    "    10: \"ADMINISTRACIÓN\",\n",
    "    11: \"CONTADURÍA\",\n",
    "    12: \"RELACIONES INDUSTRIALES\",\n",
    "    13: \"SOCIOLOGÍA\",\n",
    "    14: \"ECONOMÍA\",\n",
    "    15: \"DERECHO\",\n",
    "    16: \"TEOLOGÍA\"\n",
    "}\n",
    "\n",
    "\n",
    "# Dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar modelo con la misma configuración\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    num_labels=len(index_to_category)\n",
    ")\n",
    "model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Modo inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict carrer\n",
    "\n",
    "def predict_career(text_list, tokenizer, model, max_length=128):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()  # Índices de clase\n",
    "    predicted_labels = [index_to_category[p] for p in preds]\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def predict_career_top3(text_list, tokenizer, model, index_to_category, \n",
    "                        device, max_length=128, top_k=3, threshold=0.5):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    index_to_category: diccionario {índice: categoría}\n",
    "    device: 'cuda' o 'cpu'\n",
    "    max_length: longitud máxima de tokenización\n",
    "    top_k: número de predicciones (top) a retornar\n",
    "    threshold: umbral mínimo de probabilidad para asignar una clase (vs 'UNKNOWN')\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "\n",
    "        # Convertir logits a probabilidades con softmax\n",
    "        probs = torch.softmax(logits, dim=1)  # [batch_size, num_labels]\n",
    "        \n",
    "        # Obtener los top_k índices y probabilidades\n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "        # top_probs, top_indices => ([batch_size, top_k]), ([batch_size, top_k])\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        # Extraer las k probabilidades e índices para esta fila i\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto filtrado y concatenado\n",
    "user_text = \"\"\"\n",
    "Me gustan el inglés, biología y psicología porque me sentía conectada con esas materias. \n",
    "Por el contrario, física, química y matemática se me hicieron difíciles. \n",
    "He realizado cursos de fotografía, oratoria y modelos de naciones unidas.\n",
    "\n",
    "Disfruto correr, pintar, dormir, pasear y ver películas. Me interesan la cultura, el arte, los derechos humanos y los temas sociales. \n",
    "Aprendería más sobre periodismo de investigación y documentación, porque considero fundamental contar aquello que se mantiene oculto. \n",
    "Me motiva investigar, ayudar y enseñar.\n",
    "\n",
    "Me interesa entender cómo funciona el mundo, prefiero resolver problemas prácticos y concretos, \n",
    "disfruto trabajar con personas y ayudarlas, y me apasiona explorar culturas, ideas o filosofías. \n",
    "Visualizo un estudio creativo o colaborar con una ONG que promueva proyectos sociales.\n",
    "\n",
    "Mi meta es terminar mis dos carreras y fundar una ONG que ayude y enseñe a mujeres y niños en situaciones complejas.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "top3_preds = predict_career_top3(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    "    threshold=0.5\n",
    ")\n",
    "print(\"Top 3 predicciones:\", top3_preds[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
