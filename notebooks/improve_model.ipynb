{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el entorno y carga del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Mapea índice -> categoría (lo que usaste en training)\n",
    "index_to_category = {\n",
    "    0: \"INDUSTRIAL\", \n",
    "    1: \"CIVIL\", \n",
    "    2: \"INFORMÁTICA\",\n",
    "    3: \"TELECOMUNICACIONES\",\n",
    "    4: \"ARQUITECTURA\",\n",
    "    5: \"FILOSOFÍA\",\n",
    "    6: \"PSICOLOGÍA\",\n",
    "    7: \"LETRAS\",\n",
    "    8: \"COMUNICACIÓN SOCIAL\",\n",
    "    9: \"EDUCACIÓN\",\n",
    "    10: \"ADMINISTRACIÓN\",\n",
    "    11: \"CONTADURÍA\",\n",
    "    12: \"RELACIONES INDUSTRIALES\",\n",
    "    13: \"SOCIOLOGÍA\",\n",
    "    14: \"ECONOMÍA\",\n",
    "    15: \"DERECHO\",\n",
    "    16: \"TEOLOGÍA\"\n",
    "}\n",
    "\n",
    "\n",
    "# Dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar modelo con la misma configuración\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'dccuchile/bert-base-spanish-wwm-cased',\n",
    "    num_labels=17\n",
    ")\n",
    "model.load_state_dict(torch.load('best_model_state.bin', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Modo inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict carrer\n",
    "\n",
    "def predict_career(text_list, tokenizer, model, max_length=128):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "    \n",
    "    # Obtener predicciones\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()  # Índices de clase\n",
    "    predicted_labels = [index_to_category[p] for p in preds]\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "def predict_career_top3(text_list, tokenizer, model, index_to_category, \n",
    "                        device, max_length=128, top_k=3, threshold=0.5):\n",
    "    \"\"\"\n",
    "    text_list: lista de strings con las respuestas de usuario\n",
    "    tokenizer: tokenizer de Hugging Face\n",
    "    model: modelo BertForSequenceClassification cargado\n",
    "    index_to_category: diccionario {índice: categoría}\n",
    "    device: 'cuda' o 'cpu'\n",
    "    max_length: longitud máxima de tokenización\n",
    "    top_k: número de predicciones (top) a retornar\n",
    "    threshold: umbral mínimo de probabilidad para asignar una clase (vs 'UNKNOWN')\n",
    "    \"\"\"\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        text_list,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [batch_size, num_labels]\n",
    "\n",
    "        # Convertir logits a probabilidades con softmax\n",
    "        probs = torch.softmax(logits, dim=1)  # [batch_size, num_labels]\n",
    "        \n",
    "        # Obtener los top_k índices y probabilidades\n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "        # top_probs, top_indices => ([batch_size, top_k]), ([batch_size, top_k])\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        # Extraer las k probabilidades e índices para esta fila i\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texto filtrado y concatenado\n",
    "# Texto filtrado y concatenado\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matemática, por ser algo práctico una vez entendías el tema. \n",
    "Sin embargo, también me gustaba la materia de literatura, historia y biología. \n",
    "Educación física, soy mala en los deportes. \n",
    "Si, un curso de inglés, me gusta mucho el idioma. \n",
    "Me gusta ver series y películas, también ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnología, arte y cultura. \n",
    "Acerca de ciencia, como la teoría de la relatividad, cuántica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender cómo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas prácticos y concretos. \n",
    "En un café. \n",
    "Tecnológico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "user_text = \"\"\"Desde muy joven, he sentido una gran pasión por la tecnología. Me encanta aprender y desarrollar soluciones de software que resuelvan problemas reales; por ello, he orientado mis estudios hacia la Ingeniería Informática. Además, me fascina el mundo de las telecomunicaciones, ya que creo que conectar a las personas a través de redes modernas y eficientes es clave para el avance social y económico. Por otro lado, también me interesa la parte gerencial y organizativa, lo que me lleva a valorar la Administración; considero esencial saber planificar, gestionar proyectos y liderar equipos para llevar adelante iniciativas tecnológicas. En resumen, mi formación y mis intereses se centran en el desarrollo de sistemas informáticos, la conectividad a través de telecomunicaciones y la gestión estratégica en entornos empresariales.\"\"\"\n",
    "user_text = \"\"\"Estoy interesado en Ingeniería Industrial. Fui becado y congelé mi carrera en 2020 por temas económicos. Me gustaban las materias de Matemática e Historia de Venezuela. No me agradaban Biología y Física. Me interesa resolver problemas y explorar culturas. Me gustaría ejercer mi carrera en España y viajar por el mundo.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "top3_preds = predict_career_top3(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    "    threshold=0.5\n",
    ")\n",
    "print(\"Top 3 predicciones:\", top3_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // ... existing code ...\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Cargar el modelo de SpaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesa el texto aplicando los siguientes pasos:\n",
    "    1. Convierte a minúsculas\n",
    "    2. Elimina caracteres especiales manteniendo acentos\n",
    "    3. Elimina espacios extra\n",
    "    4. Elimina stopwords\n",
    "    5. Aplica lematización\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto a preprocesar\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto preprocesado\n",
    "    \"\"\"\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminar caracteres especiales pero mantener acentos\n",
    "    text = re.sub(r'[^a-záéíóúñü\\s]', '', text)\n",
    "    \n",
    "    # Reemplazar múltiples espacios por uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Eliminar espacios al inicio y final\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Procesar con SpaCy para lematización y eliminación de stopwords\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Unir los lemas de las palabras que no son stopwords ni puntuación\n",
    "    cleaned_text = \" \".join([token.text for token in doc if not token.is_punct])  # No eliminar stopwords ni lematizar todo\n",
    "\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def predict_career_with_preprocessing(text_list: list, tokenizer, model, \n",
    "                                   index_to_category: dict, device: str,\n",
    "                                   max_length: int = 128, top_k: int = 3, temperature: float = 1.5) -> list:\n",
    "    \"\"\"\n",
    "    Preprocesa el texto y realiza la predicción de carreras.\n",
    "    \n",
    "    Args:\n",
    "        text_list (list): Lista de textos a procesar\n",
    "        tokenizer: Tokenizer de BERT\n",
    "        model: Modelo BERT entrenado\n",
    "        index_to_category (dict): Mapeo de índices a nombres de carreras\n",
    "        device (str): Dispositivo para procesamiento ('cuda' o 'cpu')\n",
    "        max_length (int): Longitud máxima de tokens\n",
    "        top_k (int): Número de predicciones top a retornar\n",
    "        \n",
    "    Returns:\n",
    "        list: Lista de tuplas (carrera, probabilidad) para cada texto\n",
    "    \"\"\"\n",
    "    # Preprocesar cada texto\n",
    "    processed_texts = [preprocess_text(text) for text in text_list]\n",
    "    \n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(\n",
    "        processed_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Aplicar temperatura para suavizar las probabilidades\n",
    "        scaled_logits = logits / temperature\n",
    "        probs = torch.softmax(scaled_logits, dim=1)\n",
    "        \n",
    "        top_probs, top_indices = probs.topk(top_k, dim=1, largest=True, sorted=True)\n",
    "\n",
    "\n",
    "    batch_results = []\n",
    "    for i in range(len(text_list)):\n",
    "        row_probs = top_probs[i].cpu().numpy()\n",
    "        row_indices = top_indices[i].cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        for idx, p in zip(row_indices, row_probs):\n",
    "            category_name = index_to_category[idx]\n",
    "            result.append((category_name, float(p)))\n",
    "        batch_results.append(result)\n",
    "\n",
    "    return batch_results\n",
    "\n",
    "# Ejemplo de uso:\n",
    "user_text = \"\"\"Como desarrollador de IA, creo modelos para luego utilizarlos en aplicaciones. \n",
    "Me gustaba mucho la parte matemática, por ser algo práctico una vez entendías el tema. \n",
    "Sin embargo, también me gustaba la materia de literatura, historia y biología. \n",
    "Educación física, soy mala en los deportes. \n",
    "Si, un curso de inglés, me gusta mucho el idioma. \n",
    "Me gusta ver series y películas, también ver documentales o videos para aprender cosas nuevas de ciencia, historia, cultura general. \n",
    "Ciencia, tecnología, arte y cultura. \n",
    "Acerca de ciencia, como la teoría de la relatividad, cuántica, me gusta mucho entender el mundo desde esa perspectiva. \n",
    "Crear, investigar y resolver problemas. \n",
    "Me interesa entender cómo funciona el mundo, Me gusta imaginar y crear cosas nuevas, Prefiero resolver problemas prácticos y concretos. \n",
    "En un café. \n",
    "Tecnológico. \n",
    "Emprender.\"\"\"\n",
    "\n",
    "# user_text = \"\"\"Desde muy joven, he sentido una gran pasión por la tecnología. Me encanta aprender y desarrollar soluciones de software que resuelvan problemas reales; por ello, he orientado mis estudios hacia la Ingeniería Informática. Además, me fascina el mundo de las telecomunicaciones, ya que creo que conectar a las personas a través de redes modernas y eficientes es clave para el avance social y económico. Por otro lado, también me interesa la parte gerencial y organizativa, lo que me lleva a valorar la Administración; considero esencial saber planificar, gestionar proyectos y liderar equipos para llevar adelante iniciativas tecnológicas. En resumen, mi formación y mis intereses se centran en el desarrollo de sistemas informáticos, la conectividad a través de telecomunicaciones y la gestión estratégica en entornos empresariales.\"\"\"\n",
    "\n",
    "#user_text = \"\"\"Estoy interesado en Ingeniería Industrial. Fui becado y congelé mi carrera en 2020 por temas económicos. Me gustaban las materias de Matemática e Historia de Venezuela. No me agradaban Biología y Física. Me interesa resolver problemas y explorar culturas. Me gustaría ejercer mi carrera en España y viajar por el mundo.\"\"\"\n",
    "\n",
    "# Realizar predicción con el texto preprocesado\n",
    "predictions = predict_career_with_preprocessing(\n",
    "    text_list=[user_text],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    index_to_category=index_to_category,\n",
    "    device=device,\n",
    "    top_k=3,\n",
    ")\n",
    "\n",
    "print(\"Texto original:\")\n",
    "print(user_text)\n",
    "print(\"\\nTexto preprocesado:\")\n",
    "print(preprocess_text(user_text))\n",
    "print(\"\\nPredicciones:\")\n",
    "for career, prob in predictions[0]:\n",
    "    print(f\"{career}: {prob:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
