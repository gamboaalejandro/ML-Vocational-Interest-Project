{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare variables for data routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../data/raw/data_carrers.csv'\n",
    "OUTPUT_PATH = '../data/processed/processed-dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(DATASET_PATH, encoding=\"UTF-8\")\n",
    "\n",
    "# Mostrar las primeras filas para ver qué datos tenemos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data and verify cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar si hay valores nulos\n",
    "df.isnull().sum()\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "#eliminar filas duplicadas\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformando datos para analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df['CARRERA'].unique().tolist()\n",
    "\n",
    "print(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_index = {category: idx for idx, category in enumerate(categories)}\n",
    "\n",
    "# Opcional: Preprocesar texto (pasar a minúsculas, eliminar caracteres innecesarios)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convertir a minúsculas\n",
    "    text = ''.join(e for e in text if e.isalnum() or e.isspace())  # Eliminar caracteres especiales\n",
    "    return text\n",
    "\n",
    "df['TEXTO'] = df['TEXTO'].apply(preprocess_text)\n",
    "df['LABEL'] = df['CARRERA'].map(category_to_index)\n",
    "\n",
    "texts = df['TEXTO'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import accelerate\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__, accelerate.__version__)\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "#     df['TEXTO'].tolist(),\n",
    "#     df['LABEL'].tolist(),\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# print(train_texts)\n",
    "\n",
    "# print(test_texts)\n",
    "\n",
    "# print(train_labels)\n",
    "\n",
    "# print(test_labels)\n",
    "\n",
    "# train_encodings = tokenizer(\n",
    "#     train_texts,\n",
    "#     truncation=True,\n",
    "#     padding=True,\n",
    "#     max_length=128\n",
    "# )\n",
    "\n",
    "# test_encodings = tokenizer(\n",
    "#     test_texts,\n",
    "#     truncation=True,\n",
    "#     padding=True,\n",
    "#     max_length=128\n",
    "# )\n",
    "\n",
    "# class CarreraDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         item['labels'] = torch.tensor(self.labels[idx])\n",
    "#         return item\n",
    "#     def __len__(self):\n",
    "#         return len(self.labels)\n",
    "\n",
    "# train_dataset = CarreraDataset(train_encodings, train_labels)\n",
    "# test_dataset = CarreraDataset(test_encodings, test_labels)\n",
    "\n",
    "\n",
    "# # Argumentos de Entrenamiento Ajustados\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=10,            # Comienza con 10 épocas\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     warmup_steps=0,\n",
    "#     weight_decay=0.01,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=10,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"accuracy\",\n",
    "#     learning_rate=2e-5  # Tasa de aprendizaje ajustada\n",
    "# )\n",
    "\n",
    "# def compute_metrics(pred):\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions.argmax(-1)\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "#     acc = accuracy_score(labels, preds)\n",
    "#     return {\n",
    "#         'accuracy': acc,\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall\n",
    "#     }\n",
    "\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased',\n",
    "#     num_labels=len(categories)\n",
    "# )\n",
    "\n",
    "\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import numpy as np\n",
    "\n",
    "# class_weights = compute_class_weight(\n",
    "#     'balanced', \n",
    "#     classes=np.unique(train_labels), \n",
    "#     y=train_labels\n",
    "# )\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# # Actualizar la configuración del modelo\n",
    "# model.config.class_weights = class_weights\n",
    "\n",
    "# from transformers import EarlyStoppingCallback\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=test_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "# )\n",
    "\n",
    "# trainer.train()\n",
    "\n",
    "\n",
    "# # saving models\n",
    "# # trainer.save_model(\"./models/bert-base-uncased-carrera\")\n",
    "# # evaluating models\n",
    "# trainer.evaluate()\n",
    "\n",
    "labels = df['CARRERA'].map(category_to_index).tolist()  # Mapea las categorías a índices numéricos\n",
    "\n",
    "print(labels)   \n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Obtener las entradas tokenizadas\n",
    "input_ids = inputs['input_ids']\n",
    "\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Convertir las etiquetas (labels) a tensor de PyTorch\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('labels tensor',labels)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_mask, labels) # creacion de datasetObject \n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear DataLoader para cargar los datos\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained('dccuchile/bert-base-spanish-wwm-cased', \n",
    "                                    num_labels=len(category_to_index), \n",
    "                                    hidden_dropout_prob=0.3, \n",
    "                                    attention_probs_dropout_prob=0.3)\n",
    "\n",
    "# Cargar el modelo preentrenado de BERT para clasificación de secuencias\n",
    "model = BertForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-cased', config=config)\n",
    "\n",
    "# Ver el modelo cargado\n",
    "print(model)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)  # Tasa de aprendizaje 2e-5, comúnmente usada con BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Poner el modelo en modo de evaluación\n",
    "# model.eval()\n",
    "\n",
    "# # Inicializar las listas para almacenar las predicciones y las etiquetas verdaderas\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "\n",
    "# # Evaluar el modelo sin calcular gradientes\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_dataloader:\n",
    "#         input_ids, attention_mask, labels = batch\n",
    "        \n",
    "#         # Realizar la predicción\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         logits = outputs.logits\n",
    "        \n",
    "#         # Obtener la predicción más probable (la que tiene el valor más alto)\n",
    "#         preds = torch.argmax(logits, dim=1).tolist()\n",
    "        \n",
    "#         # Almacenar las predicciones y las etiquetas verdaderas\n",
    "#         predictions.extend(preds)\n",
    "#         true_labels.extend(labels.tolist())\n",
    "\n",
    "# # Mostrar un reporte de clasificación\n",
    "# print(classification_report(true_labels, predictions, target_names=category_to_index.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de épocas (epochs) para entrenar\n",
    "\n",
    "# Definir el número de épocas (epochs) y crear un scheduler para el optimizador\n",
    "epochs =17  # Puedes ajustar el número de épocas según tus necesidades\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "from tqdm import tqdm  # Para mostrar una barra de progreso\n",
    "\n",
    "# Configurar el modelo en modo de entrenamiento\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Pérdida Promedio: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Poner el modelo en modo de evaluación\n",
    "# model.eval()\n",
    "\n",
    "# # Inicializar las listas para almacenar las predicciones y las etiquetas verdaderas\n",
    "# predictions = []\n",
    "# true_labels = []\n",
    "\n",
    "# # Evaluar el modelo sin calcular gradientes\n",
    "# with torch.no_grad():\n",
    "#     for batch in test_dataloader:\n",
    "#         input_ids, attention_mask, labels = batch\n",
    "        \n",
    "#         # Realizar la predicción\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         logits = outputs.logits\n",
    "        \n",
    "#         # Obtener la predicción más probable (la que tiene el valor más alto)\n",
    "#         preds = torch.argmax(logits, dim=1).tolist()\n",
    "        \n",
    "#         # Almacenar las predicciones y las etiquetas verdaderas\n",
    "#         predictions.extend(preds)\n",
    "#         true_labels.extend(labels.tolist())\n",
    "\n",
    "# # Mostrar un reporte de clasificación\n",
    "# print(classification_report(true_labels, predictions, target_names=category_to_index.keys()))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Evaluación en el conjunto de prueba\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "test_true_labels = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluación en Conjunto de Prueba\"):\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        test_predictions.extend(preds.cpu().numpy())\n",
    "        test_true_labels.extend(labels.cpu().numpy())\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.tolist())\n",
    "        \n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = list(category_to_index.keys())\n",
    "print(classification_report(test_true_labels, test_predictions, target_names=target_names))\n",
    "\n",
    "\n",
    "# Matriz de confusión\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names, cmap='Blues')\n",
    "plt.ylabel('Etiqueta Verdadera')\n",
    "plt.xlabel('Predicción')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "target_names = list(category_to_index.keys())\n",
    "print(classification_report(true_labels, predictions, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
